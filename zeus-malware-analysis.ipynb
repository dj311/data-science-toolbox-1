{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Static Analysis and Classification of Zeus Malware\n",
    "\n",
    "The paper \" surveys a number of classification methods to differentiate binaries from the [Zeus malware family](https://en.wikipedia.org/wiki/Zeus_%28malware%29) from other types of malware. The paper used the `auto-mal` tool to perform [dynamic analysis](https://en.wikipedia.org/wiki/Dynamic_program_analysis) of the binaries as they run, creating a set of sixty-five features for each binary sample. A number of classification methods were applied and their accuracy compared.\n",
    "\n",
    "Here, the techniques used above are applied to a data set generated via [static analysis](https://en.wikipedia.org/wiki/Static_program_analysis) of malware binaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import numpy\n",
    "import pandas\n",
    "import seaborn\n",
    "import matplotlib\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn import neighbors\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Import\n",
    "\n",
    "Source the data set from static analysis of three different families of malware:\n",
    "  1. [Zeus](https://en.wikipedia.org/wiki/Zeus_%28malware%29)\n",
    "  1. [Operation Cleaver](https://en.wikipedia.org/wiki/Operation_Cleaver)\n",
    "  1. [APT-1](https://www.fireeye.com/content/dam/fireeye-www/services/pdfs/mandiant-apt1-report.pdf)\n",
    "  \n",
    "The following uses pre-analysed files, sourced from Mike Sconzo at [SecRepo](https://secrepo.com) under a [Creative Commons Attribution 4.0 International License](https://creativecommons.org/licenses/by/4.0/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "zeus = pandas.read_csv(\"resources/Zeus.csv\")  # sourced from http://www.secrepo.com/Datasets%20Description/PE_malware/Zeus.html\n",
    "zeus['Source'] = 'zeus'\n",
    "zeus.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeus.describe(include=numpy.object).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op_cleaver = pandas.read_csv(\"resources/OPCleaver.csv\")  # sourced from http://www.secrepo.com/Datasets%20Description/PE_malware/OPCleaver.html\n",
    "op_cleaver['Source'] = 'op_cleaver'\n",
    "op_cleaver.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op_cleaver.describe(include=numpy.object).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "virus_share = pandas.read_csv(\"resources/VirusShare.csv\")  # sourced from http://www.secrepo.com/Datasets%20Description/PE_malware/VirusShare.html\n",
    "virus_share['Source'] = 'virus_share'\n",
    "virus_share.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "virus_share.describe(include=numpy.object).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above data sets show 11 numerical features and 2 categorical (with the `Source` column added at import time). There is little documentation on how these features have been generated. They are a combination of PE file headers (e.g.`SectionAlignment` ), and further analysis (e.g. `HighEntropy`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleanup\n",
    "\n",
    "The Zeus and Operation Cleaver data sets both have the column \"SizeOfHeaders.1\", which is missing from the APT-1/VirusShare data set. Check that these are duplicates of the \"SizeOfHeaders\" column, then delete them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if all(zeus['SizeOfHeaders'] == zeus['SizeOfHeaders.1']):\n",
    "    del zeus['SizeOfHeaders.1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if all(op_cleaver['SizeOfHeaders'] == op_cleaver['SizeOfHeaders.1']):\n",
    "    del op_cleaver['SizeOfHeaders.1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a large size disparity between the three data sets. Combine the OpCleaver and VirusShare data sets to create a single data set with 392 non-Zeus samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_zeus = op_cleaver.append(\n",
    "    virus_share, \n",
    "    ignore_index=True,  # generate new indexes for the virus_share set\n",
    ")\n",
    "non_zeus['Source'] = 'non-zeus'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation of the data sets\n",
    "\n",
    "To mirror the work in the paper we will use an equal number of Zeus and non-Zeus samples in the learning data. Since the Zeus data set is much larger than that of the Non-Zeus data set, take a random sample of the same size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(non_zeus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeus = zeus.sample(n=392, random_state=random_seed)\n",
    "len(zeus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to split the data into training and testing sets. Inline with the paper, keep 10% of the data for testing. When doing this, we sample separately from the Zeus and non-Zeus data, this ensures the same number of Zeus and non-Zeus data points will be used during training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeus_training = zeus.sample(frac=0.9, random_state=random_seed)\n",
    "zeus_testing = zeus.drop(index=zeus_training.index)\n",
    "\n",
    "len(zeus_training), len(zeus_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_zeus_training = non_zeus.sample(frac=0.9, random_state=random_seed)\n",
    "non_zeus_testing = non_zeus.drop(index=non_zeus_training.index)\n",
    "\n",
    "len(non_zeus_training), len(non_zeus_testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mix up the zeus and non-zeus data sets, making sure to extract the 'Source' columns so they are excluded from modelling. Save these known classifications in a separate variable. This will be used during the training stage to map each entry to it's group, and the testing stage to determine the accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = zeus_training.append(non_zeus_training, ignore_index=True)\n",
    "training_source = training_set['Source']\n",
    "del training_set['Source']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_set = zeus_testing.append(non_zeus_testing, ignore_index=True)\n",
    "testing_source = testing_set['Source']\n",
    "del testing_set['Source']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The paper evaluates four methods of classifying binaries:\n",
    "  1. Support Vector Classification/Machines\n",
    "  2. Logistic Regression\n",
    "  3. Classification/Decision Trees\n",
    "  4. k-Nearest Neighbors (k-NN)\n",
    "  \n",
    "We have chosen to implement the k-NN approach described in the paper. This approach has been chosen due to it's ease of implementation using modern machine learning toolkits. In this case, we will use the `KNeighbors` classifier from [scikit-learn](http://scikit-learn.org) [1].\n",
    "\n",
    "## k-Nearest-Neighbours\n",
    "Resources:\n",
    "  - http://ogrisel.github.io/scikit-learn.org/sklearn-tutorial/auto_examples/tutorial/plot_knn_iris.html\n",
    "  - https://www.datacamp.com/community/tutorials/k-nearest-neighbor-classification-scikit-learn\n",
    "  - https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm\n",
    "  \n",
    "  \n",
    "The book \"Introduction to machine learning\" [2]  ... TODO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical values\n",
    "\n",
    "The k-NN algorithm can only be used on numeric values (since it needs to take a distance metric). For each categorical column in the data set we should either remove it, or map it into a numeric space:\n",
    "  - `TimeDateStamp` :: This can easily be mapped into a UNIX epoch, which should allow computing sane distances between times.\n",
    "  - `FileName` :: These values don't seem to be the natural filename the binaries were distributed as, and are instead a concatentation of the malware type (e.g. 'zeusbin') and a hash. This column should be removed since it gives the game away slightly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FileName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del training_set['FileName']\n",
    "training_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del testing_set['FileName']\n",
    "testing_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TimeDateStamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_time_date_stamp(time_date_stamp):\n",
    "    \"\"\"\n",
    "    Reads in a TimeDateStamp string and parses it, \n",
    "    returning a POSIX timestamp.\n",
    "    \n",
    "    Example TimeDateStamp:\n",
    "        0x50FDE944 [Tue Jan 22 01:20:04 2013 UTC]\n",
    "        \n",
    "    where 0x50FDE944 is a hex string representation\n",
    "    of the number of seconds from the UNIX epoch (in\n",
    "    UTC).\n",
    "    \"\"\"\n",
    "    hex_string = time_date_stamp.split()[0]\n",
    "    posix_timestamp = int(hex_string, 16)\n",
    "    return posix_timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example:\n",
    "import datetime\n",
    "\n",
    "example = zeus.values[0][4]\n",
    "print(example)\n",
    "\n",
    "# Parse timestamp and convert that to a Python datetime, then print it. Does it match the above?\n",
    "print(datetime.datetime.utcfromtimestamp(parse_time_date_stamp(example)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It works! Apply this conversion function to the data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set['TimeDateStamp'] = training_set['TimeDateStamp'].apply(func=parse_time_date_stamp)\n",
    "training_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_set['TimeDateStamp'] = testing_set['TimeDateStamp'].apply(func=parse_time_date_stamp)\n",
    "testing_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalising numeric values\n",
    "From https://stackabuse.com/k-nearest-neighbors-algorithm-in-python-and-scikit-learn/:\n",
    "``` py\n",
    "from sklearn.preprocessing import StandardScaler  \n",
    "scaler = StandardScaler()  \n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)  \n",
    "X_test = scaler.transform(X_test)  \n",
    "```\n",
    "\n",
    "(docs: http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler()  \n",
    "scaler.fit(training_set)\n",
    "\n",
    "training_set = scaler.transform(training_set)\n",
    "testing_set = scaler.transform(testing_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_classifier = neighbors.KNeighborsClassifier(n_neighbors=35)\n",
    "binary_classifier.fit(training_set, training_source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the classifier on the whole testing set, and use the models `.score()` method for a quick sanity check of the models accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_predictions = binary_classifier.predict(testing_set)\n",
    "binary_classifier.score(testing_set, testing_source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "The effectiveness of this model can be analysed using a [confusion matrix](https://en.wikipedia.org/wiki/Confusion_matrix). From the [documentation](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html#sklearn.metrics.confusion_matrix) of sci-kit learn:\n",
    "\n",
    ">  By definition a confusion matrix $C$ is such that $C_{i, j}$\n",
    "> is equal to the number of observations known to be in group $i$ but\n",
    "> predicted to be in group $j$.\n",
    ">\n",
    "> Thus in binary classification, the count of true negatives is\n",
    "> $C_{0,0}$, false negatives is $C_{1,0}$, true positives is\n",
    "> $C_{1,1}$ and false positives is $C_{0,1}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = metrics.confusion_matrix(testing_source, testing_predictions)\n",
    "confusion_matrix = pandas.DataFrame(\n",
    "    data=confusion_matrix, \n",
    "    index=[\n",
    "        'Non-Zeus', \n",
    "        'Zeus',\n",
    "    ], \n",
    "    columns=[\n",
    "        'Predicted Non-Zeus',\n",
    "        'Predicted Zeus'\n",
    "    ],\n",
    ")\n",
    "\n",
    "confusion_figure, confusion_axes = matplotlib.pyplot.subplots()\n",
    "seaborn.heatmap(\n",
    "    confusion_matrix,\n",
    "    annot=True,\n",
    "    fmt=\"d\",\n",
    "    cmap=seaborn.color_palette(\"Blues\"),\n",
    "    vmin=0,\n",
    "    vmax=len(testing_set),\n",
    "    ax=confusion_axes,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The specificity and sensitivity of the model can be easily computed from the confusion matrix above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_positives = confusion_matrix['Predicted Zeus']['Zeus']\n",
    "false_positives = confusion_matrix['Predicted Zeus']['Non-Zeus']\n",
    "true_negatives = confusion_matrix['Predicted Non-Zeus']['Non-Zeus']\n",
    "false_negatives = confusion_matrix['Predicted Non-Zeus']['Zeus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitivity = true_positives/(true_positives+false_negatives)\n",
    "print('Sensitivity: {:.2f}%'.format(sensitivity*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specificity = true_negatives/(true_negatives+false_positives)\n",
    "print('Specificity: {:.2f}%'.format(specificity*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Fold Validation\n",
    "  - TODO: Move the above into a repeatable unit.\n",
    "  - TODO: Use K-fold validation to more accurately score our predictions? https://en.wikipedia.org/wiki/Cross-validation_(statistics)\n",
    "     - This should decrease the variance in our accuracy score:\n",
    "     > To reduce variability, in most methods multiple rounds of cross-validation are performed using different partitions, and the validation results are combined (e.g. averaged) over the rounds to give an estimate of the modelâ€™s predictive performance. \n",
    "\n",
    "\n",
    "## Optimise number of neighbors in k-NN model\n",
    "  - TODO: Plot `num_neighbors` vs `score` (use k-fold validation for accuracy) and find the best possible value.\n",
    "  - TODO: Write up a bit about how the different distance metrics work.  \n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "[0]: Abedelaziz Mohaisen and Omar Alrawi. 2013. Unveiling Zeus: automated classification of malware samples. In Proceedings of the 22nd International Conference on World Wide Web (WWW '13 Companion). ACM, New York, NY, USA, 829-832. DOI: https://doi.org/10.1145/2487788.2488056 PDF: https://alrawi.github.io/static/papers/unzeus_www13.pdf\n",
    "\n",
    "[1]: [Scikit-learn: Machine Learning in Python](http://jmlr.csail.mit.edu/papers/v12/pedregosa11a.html), Pedregosa et al., JMLR 12, pp. 2825-2830, 2011.\n",
    "\n",
    "[2]: E. Alpaydin. Introduction to machine learning. MIT press, 2004. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "name": "Untitled.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
