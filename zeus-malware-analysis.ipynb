{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Static Analysis and Classification of Zeus Malware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas\n",
    "\n",
    "from sklearn import neighbors\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Import\n",
    "The aim of this task is to distinguish the Zeus malware from other types of malware. Load in sample describing both Zeus and other classes of malware:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "zeus = pandas.read_csv(\"resources/Zeus.csv\")\n",
    "zeus['Source'] = 'zeus'\n",
    "zeus.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op_cleaver = pandas.read_csv(\"resources/OPCleaver.csv\")\n",
    "op_cleaver['Source'] = 'op_cleaver'\n",
    "op_cleaver.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "virus_share = pandas.read_csv(\"resources/VirusShare.csv\")\n",
    "virus_share['Source'] = 'virus_share'\n",
    "virus_share.describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Zeus and OPCleaver data sets both have an extra column \"SizeOfHeaders.1\". Ensure these are just duplicates of \"SizeOfHeaders\", then delete them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if all(zeus['SizeOfHeaders'] == zeus['SizeOfHeaders.1']):\n",
    "    del zeus['SizeOfHeaders.1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if all(op_cleaver['SizeOfHeaders'] == op_cleaver['SizeOfHeaders.1']):\n",
    "    del op_cleaver['SizeOfHeaders.1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a large size disparity between the three data sets. Combine the OpCleaver and VirusShare data sets to create a single data set with 392 non-Zeus samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_zeus = op_cleaver.append(\n",
    "    virus_share, \n",
    "    ignore_index=True,  # generate new indexes for the virus_share set\n",
    ")\n",
    "non_zeus['Source'] = 'non-zeus'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation\n",
    "*Strategy:* to mirror the work in the paper we will use an equal number of Zeus and non-Zeus samples in the learning data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(non_zeus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeus = zeus.sample(n=392, random_state=random_seed)\n",
    "len(zeus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to split the data into training and testing sets. Initially, use 10% of the data for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeus_training = zeus.sample(frac=0.9, random_state=random_seed)\n",
    "zeus_testing = zeus.drop(index=zeus_training.index)\n",
    "\n",
    "len(zeus_training), len(zeus_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_zeus_training = non_zeus.sample(frac=0.9, random_state=random_seed)\n",
    "non_zeus_testing = non_zeus.drop(index=non_zeus_training.index)\n",
    "\n",
    "len(non_zeus_training), len(non_zeus_testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mix up the training and testing sets. Extract the 'Source' columns so they are excluded from modelling, but available for comparison:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = zeus_training.append(non_zeus_training, ignore_index=True)\n",
    "training_source = training_set['Source']\n",
    "del training_set['Source']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_set = zeus_training.append(non_zeus_testing, ignore_index=True)\n",
    "testing_source = testing_set['Source']\n",
    "del testing_set['Source']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The paper evaluates three methods of classifying binaries:\n",
    "  - Support Vector Classification/Machines\n",
    "  - Classification/Decision Trees\n",
    "  - K-Nearest Neighbor (KNN)\n",
    "  \n",
    "We have chosen to implement the KNN approach described in the paper. Why? It is easy to understand (and therefore analyse).\n",
    "\n",
    "## k-Nearest-Neighbours\n",
    "Resources:\n",
    "  - http://ogrisel.github.io/scikit-learn.org/sklearn-tutorial/auto_examples/tutorial/plot_knn_iris.html\n",
    "  - https://www.datacamp.com/community/tutorials/k-nearest-neighbor-classification-scikit-learn\n",
    "  - https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical values\n",
    "\n",
    "The k-NN algorithm can only be used on numeric values (since it needs to take a distance metric). For each categorical column in the data set we should either remove it, or map it into a numeric space:\n",
    "  - `TimeDateStamp` :: This can easily be mapped into a UNIX epoch, which should allow computing sane distances between times.\n",
    "  - `FileName` :: These values don't seem to be the natural filename the binaries were distributed as, and are instead a concatentation of the malware type (e.g. 'zeusbin') and a hash. This column should be removed since it gives the game away slightly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FileName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del training_set['FileName']\n",
    "training_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del testing_set['FileName']\n",
    "testing_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TimeDateStamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_time_date_stamp(time_date_stamp):\n",
    "    \"\"\"\n",
    "    Reads in a TimeDateStamp string and parses it, \n",
    "    returning a POSIX timestamp.\n",
    "    \n",
    "    Example TimeDateStamp:\n",
    "        0x50FDE944 [Tue Jan 22 01:20:04 2013 UTC]\n",
    "        \n",
    "    where 0x50FDE944 is a hex string representation\n",
    "    of the number of seconds from the UNIX epoch (in\n",
    "    UTC).\n",
    "    \"\"\"\n",
    "    hex_string = time_date_stamp.split()[0]\n",
    "    posix_timestamp = int(hex_string, 16)\n",
    "    return posix_timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example:\n",
    "import datetime\n",
    "\n",
    "example = zeus.values[0][4]\n",
    "print(example)\n",
    "\n",
    "# Parse timestamp and convert that to a Python datetime, then print it. Does it match the above?\n",
    "print(datetime.datetime.utcfromtimestamp(parse_time_date_stamp(example)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It works! Apply this conversion function to the data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set['TimeDateStamp'] = training_set['TimeDateStamp'].apply(func=parse_time_date_stamp)\n",
    "training_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_set['TimeDateStamp'] = testing_set['TimeDateStamp'].apply(func=parse_time_date_stamp)\n",
    "testing_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalising numeric values\n",
    "From https://stackabuse.com/k-nearest-neighbors-algorithm-in-python-and-scikit-learn/:\n",
    "``` py\n",
    "from sklearn.preprocessing import StandardScaler  \n",
    "scaler = StandardScaler()  \n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)  \n",
    "X_test = scaler.transform(X_test)  \n",
    "```\n",
    "\n",
    "(docs: http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler()  \n",
    "scaler.fit(training_set)\n",
    "\n",
    "training_set = scaler.transform(training_set)\n",
    "testing_set = scaler.transform(testing_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_classifier = neighbors.KNeighborsClassifier(n_neighbors=39)\n",
    "binary_classifier.fit(training_set, training_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_classifier.score(testing_set, testing_source)  # (quick sanity check)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "\n",
    "  - TODO: Analyse accuracy of model (false, true x positive, negatives). Qualitive analysis of what this means (too many false positive is bad?)\n",
    "  - TODO: Plot graph of neighbours ala http://ogrisel.github.io/scikit-learn.org/sklearn-tutorial/auto_examples/tutorial/plot_knn_iris.html\n",
    "\n",
    "\n",
    "\n",
    "## K-Fold Validation\n",
    "  - TODO: Move the above into a repeatable unit.\n",
    "  - TODO: Use K-fold validation to more accurately score our predictions?\n",
    "\n",
    "    \n",
    "\n",
    "## Optimise number of neighbors in k-NN model\n",
    "\n",
    "  - TODO: Plot `num_neighbors` vs `score` (use k-fold validation for accuracy) and find the best possible value.\n",
    "  - TODO: Write up a bit about how the different distance metrics work.  \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "name": "Untitled.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
